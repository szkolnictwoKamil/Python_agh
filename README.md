# Python_agh
This repository contains the code I wrote for my Python classes during my Master's studies. Below is a quick summary of each task:

- task_1: This code implements the **Aho-Corasick** algorithm, used for multi-pattern search in a single pass through the text. 
- task_2: This code implements a graph as a data structure and provides various methods for manipulating vertices, edges, and performing traversal algorithms such as DFS (Depth-First Search) and BFS (Breadth-First Search).
- task_3: This code counts word occurrences in a text file without loading the entire file into memory and returns the most frequently occurring words.
- task_4: This code allows the user to log in with a specific role, connect to a library database, and access functions such as borrowing a book, extending a loan, returning a book, etc., based on their role. The actions also update the database accordingly.
- task_5: This code implements a custom K-Nearest Neighbors (KNN) classifier, allowing users to classify data points based on proximity to training samples. It supports multiple distance metrics (e.g., Euclidean, Manhattan, Cosine) and both uniform and distance-based weighting. The model is trained on a dataset (dataset1.csv), split into training and testing sets, and provides methods for predicting classes, finding neighbors, and evaluating accuracy. Finally, it writes the training data back to a CSV file (dane.csv).
- task_6: This code is a simple data analysis notebook with a few useful Pandas functions.
- task_7: This code trains and evaluates three machine learning classifiers (SVM, kNN, and Decision Tree) on a dataset of text documents. The documents are processed by extracting n-grams (unigrams, bigrams, or trigrams) from the text, and then each classifier is trained on different configurations of the n-gram length and chunk size. The performance of the models is evaluated using accuracy, precision, recall, and F1 score, and the results are logged and saved to a CSV file. Key steps include text preprocessing (removing special characters, digits, and normalizing), extracting features from the text, and scaling the data before training. The code also includes logging and progress tracking using `tqdm`.